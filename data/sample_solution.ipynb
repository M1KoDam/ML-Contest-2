{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/alexander/Desktop/ml2024/snd_contest_1/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision torchaudio catboost pandas transformers[torch] evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import pylab as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Выбор чисто на 3/5. Магазинов мало, развлечени...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Сегодня, 25.05.2023 заказывал шаурму в тарелке...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ходила сегодня первый раз, записывалась через ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ремонтировали тут айфон ХS, меняли камеру и эк...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Очень уютный кинотеатр, как любой другой от ко...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating\n",
       "0  Выбор чисто на 3/5. Магазинов мало, развлечени...     3.0\n",
       "1  Сегодня, 25.05.2023 заказывал шаурму в тарелке...     5.0\n",
       "2  Ходила сегодня первый раз, записывалась через ...     5.0\n",
       "3  Ремонтировали тут айфон ХS, меняли камеру и эк...     5.0\n",
       "4  Очень уютный кинотеатр, как любой другой от ко...     5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим \"в лоб\" катбуст\n",
    "Жизнь слишком коротка, чтобы чистить или даже просматривать данные, просто жахнем обучение, а с качеством - будь что будет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c8b5506f4e486a91df0c51200d9493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4613197061\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4580813568\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4573849493\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4576870433\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.4580195776\n",
      "bestIteration = 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'loss_function': 'MAE',\n",
    "    'iterations': 150,\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.05\n",
    "}\n",
    "\n",
    "pool = cb.Pool(data[['text']], data.rating, text_features=['text'])\n",
    "cv_res = cb.cv(\n",
    "  params=params, \n",
    "  pool=pool, \n",
    "  early_stopping_rounds=30, \n",
    "  fold_count=5, \n",
    "  shuffle=True, \n",
    "  partition_random_seed=0,\n",
    "  plot=True, \n",
    "  stratified=True, \n",
    "  verbose=False,\n",
    "  return_models=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     iterations  test-MAE-mean  test-MAE-std  train-MAE-mean  train-MAE-std\n",
       " 0             0       4.231884      0.000108        4.231883       0.000107\n",
       " 1             1       3.995066      0.000864        3.995049       0.000841\n",
       " 2             2       3.769738      0.001082        3.769721       0.001066\n",
       " 3             3       3.555979      0.001088        3.555956       0.001069\n",
       " 4             4       3.370099      0.000628        3.370081       0.000622\n",
       " ..          ...            ...           ...             ...            ...\n",
       " 145         145       0.459154      0.001622        0.458168       0.000870\n",
       " 146         146       0.458979      0.001577        0.457986       0.000861\n",
       " 147         147       0.458770      0.001531        0.457768       0.000860\n",
       " 148         148       0.458620      0.001573        0.457614       0.000857\n",
       " 149         149       0.458499      0.001602        0.457487       0.000824\n",
       " \n",
       " [150 rows x 5 columns],\n",
       " [<catboost.core.CatBoost at 0x7b8a2602f2e0>,\n",
       "  <catboost.core.CatBoost at 0x7b8a2602f0d0>,\n",
       "  <catboost.core.CatBoost at 0x7b8a2602f3a0>,\n",
       "  <catboost.core.CatBoost at 0x7b8a201b9bb0>,\n",
       "  <catboost.core.CatBoost at 0x7b8a201b9ca0>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну везде примерно 0.45 средняя абсолютная ошибка. Помним, что жизнь коротка: отдельного валсета мы  от трейна не отщепили и теперь не можем в честном сетапе глянуть глазами как оно предсказывает на новых данных. Не можем чекнуть перфоманс на единицах и пятёрках отдельно. В рамках текущей демнострации предлагается с этим просто смириться. Что ж, сделаем сабмит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240021</td>\n",
       "      <td>Хорошая и качественная выпечка и  шавуха. Одна...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345218</td>\n",
       "      <td>Была у вас в гостях недавно в первый раз, подр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201829</td>\n",
       "      <td>Любим посещать остров сокровищ. Постоянно здес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458075</td>\n",
       "      <td>Хочу выразить благодарность автошколе «Позитив...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5940</td>\n",
       "      <td>Всё супер!  Очень вежливые сотрудники, как к р...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               text\n",
       "0  240021  Хорошая и качественная выпечка и  шавуха. Одна...\n",
       "1  345218  Была у вас в гостях недавно в первый раз, подр...\n",
       "2  201829  Любим посещать остров сокровищ. Постоянно здес...\n",
       "3  458075  Хочу выразить благодарность автошколе «Позитив...\n",
       "4    5940  Всё супер!  Очень вежливые сотрудники, как к р..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv('test.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv_res[1][0]\n",
    "preds = model.predict(df_sub[['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глянем на предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.hist(preds)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Штош, они как минимум разные. Решено, засылаем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['rating'] = preds\n",
    "df_sub[['ID', 'rating']].to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Воспользуемся предобученной трансформерной моделью для перевода предложений в векторы\n",
    "\n",
    "Например [этой](https://huggingface.co/cointegrated/rubert-tiny2). А потом попробуем поверх векторов что-нибудь дообучить под предсказание рейтинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "text_to_vec_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "text_to_vec_model.cuda()  # uncomment it if you have a GPU\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt',) # разобьём текст на токены из словаря, на котором училась модель\n",
    "    with torch.no_grad():  # градиенты не нужны, мы пока не учимся, а просто прогоняем данные через модель. Сэкономим памяти.\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()}) # Это мы результат токенизации на ГПУ перегоняем, если надо и в модельку перелаём \n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)  # Нормализуем эмбеддинги, чтобы они были с единичной сферы. \n",
    "    # Теперь не придётся в дальнейшем думать, чувствительны ли наши алгоритмы к норме векторов\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03994568 -0.00592288  0.01523517 -0.04026827 -0.02025329 -0.00433577\n",
      "   0.01105824  0.02046457  0.0070199   0.04463923]] (1, 312)\n"
     ]
    }
   ],
   "source": [
    "maybe_vector = embed_bert_cls(\"это точно работает?\", text_to_vec_model, tokenizer)\n",
    "print(maybe_vector[:, :10], maybe_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   280, 24302,  2317,   775, 18125,  1046, 59853,    35,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"А токенайзер что отдаёт?\", padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input ids` - это номера в словаре для токенов, на которые разбился наш текст. [token_type_ids](https://huggingface.co/transformers/v3.2.0/glossary.html#token-type-ids) нам для задачи \"просто сделай векторы из обычных текстов\" не важны, а `attention_mask` из единичек разрешает модели \"смотреть\" через механизм attention на всё предложение, когда она будет обрабатывать конкретные токены из последовательности, которую мы им скормим.\n",
    "\n",
    "Сделаем векторы из наших текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:45<00:00, 151.07it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16  # если используется ГПУ и падает по CUDA out of memory, то размер батча можно уменьшить\n",
    "vectors = []\n",
    "for i in tqdm(range(0,int(len(data)/batch_size))):\n",
    "    data_batch = data['text'][i*batch_size: (i+1)*batch_size].tolist()\n",
    "    embeddings = embed_bert_cls(data_batch, text_to_vec_model, tokenizer)\n",
    "    vectors.extend(embeddings)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312,), 400000, 400000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0].shape, len(vectors), len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Засунем векторы в точно такой же катбуст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335869cccb764acbbe7c0f9625cce457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.3816491399\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.3801046379\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.3777807693\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.3785934981\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.3793707346\n",
      "bestIteration = 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'loss_function': 'MAE',\n",
    "    'iterations': 150,\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.05\n",
    "}\n",
    "\n",
    "pool = cb.Pool(vectors, data.rating)\n",
    "cv_res = cb.cv(\n",
    "  params=params, \n",
    "  pool=pool, \n",
    "  early_stopping_rounds=30, \n",
    "  fold_count=5, \n",
    "  shuffle=True, \n",
    "  partition_random_seed=0,\n",
    "  plot=True, \n",
    "  stratified=True, \n",
    "  verbose=False,\n",
    "  return_models=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало 0.38! Сделаем сабмишен, не забыв векторизовать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [00:40<00:00, 152.74it/s]\n"
     ]
    }
   ],
   "source": [
    "model = cv_res[1][0]\n",
    "\n",
    "batch_size = 16  # если используется ГПУ и падает по CUDA out of memory, то размер батча можно уменьшить\n",
    "vectors_sub = []\n",
    "for i in tqdm(range(0,int(len(df_sub)/batch_size))):\n",
    "    data_batch = df_sub['text'][i*batch_size: (i+1)*batch_size].tolist()\n",
    "    embeddings = embed_bert_cls(data_batch, text_to_vec_model, tokenizer)\n",
    "    vectors_sub.extend(embeddings)\n",
    "   \n",
    "preds = model.predict(vectors_sub)\n",
    "df_sub['rating'] = preds\n",
    "df_sub[['ID', 'rating']].to_csv('sub_bert_catboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, попробуем дообучить нашу модель под именно наши данные и нашу задачу и посмотреть, окажет ли это эффект. Будем заставлять модельку напрямую прогнозировать наш рейтинг, не наворачивая поверх катбуст. \n",
    "\n",
    "Кросс-валидация тут будет дорогой: трансформерные модельки учатся существенно дольше, чем катбуст, так что отщепим кусочек данных для тестирования нашего перфоманса\n",
    "\n",
    "\n",
    "Ниже не будет готового решения, лишь несколько импортов, чтобы указать куда копать. Результат, который можно выбить на этом пути разумными усилиями можно увидеть в лидерборде от участника Alexander :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.15, stratify=data['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы стандартный инструмент для трейна моделей из библиотеки transformers работал, и нам не надо было руками писать трейнлуп и логирование, завернём наши данные в класс Dataset, а его в Dataloader. Их два, т.к. датасет описывает как из сырцов получать данные для модели, а даталоадер - это про эффективную итерацию, prefetch и тому подобное "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_length):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        tokens = tokenizer(review, padding='max_length', truncation=True, return_tensors='pt',max_length=self.max_length)\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokens['input_ids'].flatten(),\n",
    "            'attention_mask': tokens['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['text'].values, train['rating'].values, tokenizer, 256)\n",
    "test_dataset = CustomDataset(test['text'].values, test['rating'].values, tokenizer, 256)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True) # если используется ГПУ и падает по CUDA out of memory, то размер батча можно уменьшить\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=False) # если используется ГПУ и падает по CUDA out of memory, то размер батча можно уменьшить"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
